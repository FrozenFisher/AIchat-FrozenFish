# 情感音频生成功能使用指南

## 功能概述

本系统集成了BERT情感分析模型，能够根据文本内容自动识别情感类型，并选择对应的参考音频进行语音合成，实现更自然、更有情感色彩的语音输出。

## 支持的情感类型

系统支持以下15种情感类型：

1. **高兴** - 快乐、愉悦的情感
2. **悲伤** - 难过、伤心的情感  
3. **愤怒** - 生气、愤怒的情感
4. **惊讶** - 震惊、意外的情感
5. **恐惧** - 害怕、恐惧的情感
6. **厌恶** - 讨厌、反感的情感
7. **中性** - 平静、客观的情感
8. **害羞** - 羞涩、不好意思的情感
9. **兴奋** - 激动、兴奋的情感
10. **舒适** - 放松、舒适的情感
11. **紧张** - 紧张、焦虑的情感
12. **爱慕** - 喜欢、爱慕的情感
13. **委屈** - 委屈、不满的情感
14. **骄傲** - 自豪、骄傲的情感
15. **困惑** - 疑惑、困惑的情感

## 文件结构

```
lib/参考音频/
├── 高兴/
│   ├── 银狼_高兴.wav
│   ├── 温迪_高兴.wav
│   ├── 流萤_高兴.wav
│   └── 潘兴_高兴.wav
├── 悲伤/
│   ├── 银狼_悲伤.wav
│   ├── 温迪_悲伤.wav
│   ├── 流萤_悲伤.wav
│   └── 潘兴_悲伤.wav
├── 愤怒/
│   └── ...
├── 惊讶/
│   └── ...
├── 恐惧/
│   └── ...
├── 厌恶/
│   └── ...
├── 中性/
│   └── ...
├── 害羞/
│   └── ...
├── 兴奋/
│   └── ...
├── 舒适/
│   └── ...
├── 紧张/
│   └── ...
├── 爱慕/
│   └── ...
├── 委屈/
│   └── ...
├── 骄傲/
│   └── ...
└── 困惑/
    └── ...
```

## 配置说明

### 1. 模型配置文件 (modelconfig.yaml)

每个角色现在支持多种情感的参考音频：

```yaml
Agents:
  银狼:
    GPTPath: GPT_weights_v2/银狼-e10.ckpt
    SoVITSPath: SoVITS_weights_v2/银狼_e15_s480.pth
    bgPath: lib/bg/bgSilverWolf.png
    promptPath: lib/prompt/promptSilverWolf.txt
    refaudioPath:
      高兴: lib/参考音频/高兴/银狼_高兴.wav
      悲伤: lib/参考音频/悲伤/银狼_悲伤.wav
      愤怒: lib/参考音频/愤怒/银狼_愤怒.wav
      # ... 其他情感
```

### 2. BERT模型路径

BERT情感分析模型位于：`lib/retrainedBERT/`

## 使用方法

### 1. 准备参考音频

为每个角色准备14种情感的参考音频文件，命名格式为：`角色名_情感.wav`

例如：
- `银狼_高兴.wav`
- `温迪_悲伤.wav`
- `流萤_愤怒.wav`

### 2. 启动服务器

```bash
python server.py
```

服务器启动时会自动加载BERT情感分析模型。

### 3. 测试情感分析

```bash
# 测试情感分析功能
curl -X POST "http://localhost:8000/emotion/analyze?text=我今天特别开心！"

# 查看模型状态
curl -X GET "http://localhost:8000/emotion/status"
```

### 4. 聊天测试

```bash
# 发送聊天消息，系统会自动分析情感并选择对应音频
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "我今天特别开心！",
    "agent": "银狼"
  }'
```

## API接口

### 1. 情感分析接口

**POST** `/emotion/analyze`

分析文本情感类型

**参数：**
- `text` (string): 要分析的文本

**返回：**
```json
{
  "text": "我今天特别开心！",
  "emotion": "高兴",
  "message": "情感分析完成"
}
```

### 2. 情感分析状态接口

**GET** `/emotion/status`

获取情感分析模型状态

**返回：**
```json
{
  "bert_loaded": true,
  "device": "CPU",
  "available_emotions": ["高兴", "悲伤", "愤怒", ...]
}
```

## 工作流程

1. **文本输入** - 用户发送聊天消息
2. **情感分析** - BERT模型分析文本情感
3. **音频选择** - 根据情感选择对应参考音频
4. **语音合成** - 使用GPT-SoVITS生成语音
5. **音频返回** - 返回base64编码的音频数据

## 注意事项

1. **音频文件要求**：
   - 格式：WAV
   - 时长：建议5-15秒
   - 质量：清晰、无噪音
   - 情感表达：明确、自然

2. **模型要求**：
   - BERT模型必须位于 `lib/retrainedBERT/` 目录
   - 需要安装 transformers 和 torch 库

3. **性能考虑**：
   - 首次加载BERT模型需要时间
   - 情感分析会增加少量延迟
   - 建议使用GPU加速（如果可用）

## 故障排除

### 1. BERT模型加载失败

**症状：** 服务器启动时显示"BERT模型加载失败"

**解决方案：**
- 检查 `lib/retrainedBERT/` 目录是否存在
- 确认模型文件完整（config.json, model.safetensors, vocab.txt等）
- 检查依赖库是否正确安装

### 2. 参考音频不存在

**症状：** 日志显示"参考音频不存在"

**解决方案：**
- 检查音频文件路径是否正确
- 确认音频文件是否存在
- 检查文件名格式是否正确

### 3. 情感分析不准确

**症状：** 情感识别结果不符合预期

**解决方案：**
- 检查训练数据质量
- 考虑重新训练BERT模型
- 调整情感阈值

## 扩展功能

### 1. 情感强度

可以扩展为支持情感强度分析，如"很高兴"、"有点难过"等。

### 2. 混合情感

支持多种情感的混合识别，如"又惊又喜"。

### 3. 上下文分析

考虑对话上下文进行更准确的情感分析。

### 4. 个性化调整

允许用户调整情感识别的敏感度。 