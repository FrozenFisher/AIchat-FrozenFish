#!/usr/bin/env python3
"""
Ollamaå®‰è£…å’Œé…ç½®è„šæœ¬
"""

import subprocess
import sys
import platform
import requests
import json
from pathlib import Path

def check_ollama_installed():
    """æ£€æŸ¥Ollamaæ˜¯å¦å·²å®‰è£…"""
    try:
        result = subprocess.run(['ollama', '--version'], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print(f"âœ… Ollamaå·²å®‰è£…: {result.stdout.strip()}")
            return True
        else:
            return False
    except (subprocess.TimeoutExpired, FileNotFoundError):
        return False

def install_ollama():
    """å®‰è£…Ollama"""
    system = platform.system().lower()
    
    print(f"ğŸ”§ æ£€æµ‹åˆ°ç³»ç»Ÿ: {system}")
    
    if system == "darwin":  # macOS
        print("ğŸ“¦ åœ¨macOSä¸Šå®‰è£…Ollama...")
        try:
            subprocess.run([
                "curl", "-fsSL", "https://ollama.ai/install.sh", "|", "sh"
            ], shell=True, check=True)
            print("âœ… Ollamaå®‰è£…å®Œæˆ")
            return True
        except subprocess.CalledProcessError as e:
            print(f"âŒ Ollamaå®‰è£…å¤±è´¥: {e}")
            return False
    
    elif system == "linux":
        print("ğŸ“¦ åœ¨Linuxä¸Šå®‰è£…Ollama...")
        try:
            subprocess.run([
                "curl", "-fsSL", "https://ollama.ai/install.sh", "|", "sh"
            ], shell=True, check=True)
            print("âœ… Ollamaå®‰è£…å®Œæˆ")
            return True
        except subprocess.CalledProcessError as e:
            print(f"âŒ Ollamaå®‰è£…å¤±è´¥: {e}")
            return False
    
    elif system == "windows":
        print("ğŸ“¦ åœ¨Windowsä¸Šå®‰è£…Ollama...")
        print("è¯·è®¿é—® https://ollama.ai/download ä¸‹è½½Windowsç‰ˆæœ¬")
        return False
    
    else:
        print(f"âŒ ä¸æ”¯æŒçš„æ“ä½œç³»ç»Ÿ: {system}")
        return False

def start_ollama_service():
    """å¯åŠ¨OllamaæœåŠ¡"""
    print("ğŸš€ å¯åŠ¨OllamaæœåŠ¡...")
    try:
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²åœ¨è¿è¡Œ
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            print("âœ… OllamaæœåŠ¡å·²åœ¨è¿è¡Œ")
            return True
    except requests.exceptions.RequestException:
        pass
    
    try:
        # å¯åŠ¨OllamaæœåŠ¡
        process = subprocess.Popen(['ollama', 'serve'], 
                                 stdout=subprocess.PIPE, 
                                 stderr=subprocess.PIPE)
        
        # ç­‰å¾…æœåŠ¡å¯åŠ¨
        import time
        for i in range(30):  # æœ€å¤šç­‰å¾…30ç§’
            try:
                response = requests.get("http://localhost:11434/api/tags", timeout=2)
                if response.status_code == 200:
                    print("âœ… OllamaæœåŠ¡å¯åŠ¨æˆåŠŸ")
                    return True
            except requests.exceptions.RequestException:
                pass
            
            print(f"â³ ç­‰å¾…OllamaæœåŠ¡å¯åŠ¨... ({i+1}/30)")
            time.sleep(1)
        
        print("âŒ OllamaæœåŠ¡å¯åŠ¨è¶…æ—¶")
        return False
        
    except Exception as e:
        print(f"âŒ å¯åŠ¨OllamaæœåŠ¡å¤±è´¥: {e}")
        return False

def download_model(model_name="qwen3:8b"):
    """ä¸‹è½½Ollamaæ¨¡å‹"""
    print(f"ğŸ“¥ ä¸‹è½½æ¨¡å‹: {model_name}")
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å­˜åœ¨
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            models = response.json()
            existing_models = [model["name"] for model in models["models"]]
            if model_name in existing_models:
                print(f"âœ… æ¨¡å‹ {model_name} å·²å­˜åœ¨")
                return True
        
        # ä¸‹è½½æ¨¡å‹
        print(f"â³ å¼€å§‹ä¸‹è½½æ¨¡å‹ {model_name}...")
        result = subprocess.run(['ollama', 'pull', model_name], 
                              capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… æ¨¡å‹ {model_name} ä¸‹è½½å®Œæˆ")
            return True
        else:
            print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {result.stderr}")
            return False
            
    except Exception as e:
        print(f"âŒ ä¸‹è½½æ¨¡å‹å¤±è´¥: {e}")
        return False

def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
    print("ğŸ“‹ åˆ—å‡ºå¯ç”¨æ¨¡å‹...")
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            models = response.json()
            if "models" in models and models["models"]:
                print("âœ… å¯ç”¨æ¨¡å‹:")
                for model in models["models"]:
                    print(f"   - {model['name']} ({model.get('size', 'N/A')})")
                return models["models"]
            else:
                print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ç”¨æ¨¡å‹")
                return []
        else:
            print("âŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨")
            return []
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []

def test_model(model_name="qwen3:8b"):
    """æµ‹è¯•æ¨¡å‹"""
    print(f"ğŸ§ª æµ‹è¯•æ¨¡å‹: {model_name}")
    try:
        test_data = {
            "model": model_name,
            "messages": [{"role": "user", "content": "ä½ å¥½"}],
            "stream": False
        }
        
        response = requests.post(
            "http://localhost:11434/api/chat",
            json=test_data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸ")
            print(f"   å›å¤: {result['message']['content'][:100]}...")
            return True
        else:
            print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ Ollamaå®‰è£…å’Œé…ç½®è„šæœ¬")
    print("=" * 50)
    
    # æ£€æŸ¥æ˜¯å¦å·²å®‰è£…
    if not check_ollama_installed():
        print("ğŸ“¦ Ollamaæœªå®‰è£…ï¼Œå¼€å§‹å®‰è£…...")
        if not install_ollama():
            print("âŒ å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…Ollama")
            return False
    
    # å¯åŠ¨æœåŠ¡
    if not start_ollama_service():
        print("âŒ æ— æ³•å¯åŠ¨OllamaæœåŠ¡")
        return False
    
    # ä¸‹è½½é»˜è®¤æ¨¡å‹
    if not download_model("qwen3:8b"):
        print("âŒ æ— æ³•ä¸‹è½½é»˜è®¤æ¨¡å‹")
        return False
    
    # åˆ—å‡ºæ¨¡å‹
    models = list_models()
    
    # æµ‹è¯•æ¨¡å‹
    if not test_model("qwen3:8b"):
        print("âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥")
        return False
    
    print("\nğŸ‰ Ollamaé…ç½®å®Œæˆ!")
    print("ç°åœ¨å¯ä»¥è¿è¡Œ: python start_server.py")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 